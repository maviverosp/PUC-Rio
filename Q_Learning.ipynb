{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOKGQsX/OLL/7U9WbWJao/W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maviverosp/PUC-Rio/blob/main/Q_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTHOwP7vR7km",
        "outputId": "cdb5b218-ebcf-4886-efd3-0af861bff29d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym) (0.0.8)\n"
          ]
        }
      ],
      "source": [
        "#Biblioteca GYM\n",
        "#Install the dependencies on Google Colab\n",
        "\n",
        "!pip install numpy\n",
        "!pip install gym"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Etapa 0: Importar las dependencias\n",
        "Usamos tres bibliotecas\n",
        "- **\"Numpy\"** para nuestra Qtable\n",
        "- **\"OpenAI GyM\"** para nuestro ambiente FrozenLake\n",
        "- **\"Random\"** para generar numeros aleatrotios"
      ],
      "metadata": {
        "id": "6QRAeyiVYRRL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "import random\n"
      ],
      "metadata": {
        "id": "K3YvEQpNXaGX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Etapa 1: Crear el ambiente\n",
        "1. Aqui vamos a crear el ambiente FrozenLake 8x8.\n",
        "2. OpenAi GyM es una biblioteca compuesta por varios ambientes que podemos usar para entrenar nuestros agentes.\n",
        "3. En nuestro caso optamos por usar Frozen Lake."
      ],
      "metadata": {
        "id": "pN-6eC_NYzSu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make(\"FrozenLake-v1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNaRkzI4Yx65",
        "outputId": "4385bdde-e2a5-4627-9022-7af8380e3d6b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Etapa 2: Crear la tabla Q e iniciela\n",
        "- Ahora, vamos a crear nuestra tabla Q, para saber de cuantas lineas (estados) e columnas (acciones) necesitamos, se requiere calcular el action_size o state_size.\n",
        "- OpenAI GyM nos entrega una manera de hacer eso: `env.action_space.n` y `env.observation_space.n`"
      ],
      "metadata": {
        "id": "z8sRJKacZocI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "action_size = env.action_space.n\n",
        "state_size = env.observation_space.n"
      ],
      "metadata": {
        "id": "R6EsSzYgalB2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Vamos a crear nuestro tabla Q con state_size (lineas) y action_size columns (64x4)\n",
        "qtable = np.zeros((state_size, action_size))\n",
        "print(qtable)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJFTWLaFbFMZ",
        "outputId": "8166e39c-4166-49e6-97d4-4b1614834fff"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Etapa 3: Crear los hiperparámetros\n",
        "Aqui las especificaremos los hiperparámetros.\n",
        "\n"
      ],
      "metadata": {
        "id": "hoAiG4_ecLy6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_episodes = 50000 #Total Episodes\n",
        "learning_rate = 0.7 #Learning Rate\n",
        "max_steps = 99 #Max Steps per episodes\n",
        "gamma = 0.95 #Discount rate\n",
        "\n",
        "#Exploration parametres\n",
        "epsilon = 1.0 #Exploration rate\n",
        "max_epsilon = 1.0 #Exploration probability at start\n",
        "min_epsilon = 0.01 #Minimun exploration probability\n",
        "decay_rate = 0.005 # Exponential decay rate for exploration prob."
      ],
      "metadata": {
        "id": "0HVicXaVcKCu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Etapa 4: El algoritmo de aprendizaje Q\n",
        "Ahora implementaremos el algoritmo de aprendizaje Q:\n",
        "  ![alt text](http://simoninithomas.com/drlc/Qlearning//qtable_algo.png)"
      ],
      "metadata": {
        "id": "-FwBiJHgdnLd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de rewards\n",
        "rewards = []\n",
        "\n",
        "# 2 for life or until learning is stopped\n",
        "for episode in range(total_episodes):\n",
        "  #Reset de environment\n",
        "  state = env.reset()\n",
        "  step = 0\n",
        "  done = False\n",
        "  total_rewards = 0\n",
        "\n",
        "  for step in range(max_steps):\n",
        "    # 3. Choose an action a in the corrent world state (s)\n",
        "    ##Firt we randomize a number\n",
        "    exp_exp_tradeoff = random.uniform(0, 1)\n",
        "\n",
        "    ## If this number > greater than epsilon --> exploration (taking the biggest Q value for this state)\n",
        "    if exp_exp_tradeoff > epsilon:\n",
        "      action = np.argmax(qtable[state,:])\n",
        "      #print(exp_exp_tradeoff, \"action\", action)\n",
        "\n",
        "    #Else doing a random choice --> exploration\n",
        "    else:\n",
        "      action = env.action_space.sample()\n",
        "      #print(\"action random\", action)\n",
        "\n",
        "    #Takke the action (a) and observe the outcome state(s') and reward (r)\n",
        "    new_state, reward, done, info = env.step(action)\n",
        "\n",
        "    #Update Q(s,a) := Q(s,a) + lr [R(s,a)] + gamma * max Q(s', a') - Q(s,a)]\n",
        "    #Qtable [new_state,:] : all teh actions we can take from new state\n",
        "    qtable[state, action] = qtable[state, action] + learning_rate * (reward + gamma * np.max(qtable[new_state,:]) - qtable[state, action])\n",
        "\n",
        "    total_rewards += reward\n",
        "\n",
        "    #Our new state is state\n",
        "    state = new_state\n",
        "\n",
        "    #If done (if we're dead) : finish episode\n",
        "    if done == True:\n",
        "      break\n",
        "\n",
        "  #Reduce epsilon (Because we need less and less exploration)\n",
        "  epsilon = min_epsilon + (max_epsilon - min_epsilon) * np.exp(-decay_rate*episode)\n",
        "  rewards.append(total_rewards)\n",
        "\n",
        "print(\"Score over time: \" + str(sum(rewards)/total_episodes))\n",
        "\n",
        "print(qtable)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xToGjpwAdlqv",
        "outputId": "6f1b1d74-34a8-456b-ac76-026d7e2e7316"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(terminated, (bool, np.bool8)):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score over time: 0.50328\n",
            "[[2.06281740e-01 1.10534205e-01 1.18549231e-01 1.39500812e-01]\n",
            " [1.07521374e-02 2.37662494e-02 1.02187560e-02 7.45196401e-02]\n",
            " [9.94001123e-03 4.28311598e-01 2.18054973e-02 2.80760114e-02]\n",
            " [2.02938987e-03 4.09266244e-03 1.31207876e-02 1.05352466e-01]\n",
            " [2.62133301e-01 6.43447753e-02 4.64037477e-02 3.87782741e-02]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [2.21100320e-04 2.94774127e-06 1.36709504e-01 3.44607818e-05]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [2.25027229e-02 1.58870643e-02 2.65886648e-02 2.89130058e-01]\n",
            " [1.17004770e-02 5.72184580e-01 9.37820393e-04 1.53286727e-02]\n",
            " [6.05082751e-03 8.46973483e-01 3.89494362e-03 5.60471728e-04]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [1.14875726e-01 1.37896293e-04 4.93883418e-01 1.60445654e-01]\n",
            " [5.33320225e-01 6.23059641e-01 9.36968086e-01 2.91523354e-01]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.reset()\n",
        "\n",
        "for episode in range(10):\n",
        "    state = env.reset()\n",
        "    step = 0\n",
        "    done = False\n",
        "    print(\"*************************************************\")\n",
        "    print(\"Episode: \", episode)\n",
        "\n",
        "    for step in range(max_steps):\n",
        "\n",
        "        #Take the action (index) that have the maximum expected future reward given that state\n",
        "        action = np.argmax(qtable[state,:])\n",
        "\n",
        "        new_state, reward, done, infor = env.step(action)\n",
        "\n",
        "        if done:\n",
        "            #Here, we decide to only print the last state (to see of our agent is on the goal or fall into an hole)\n",
        "            env.render()\n",
        "            if new_state == 15:\n",
        "                print(\"We reached our Goal 🏆 \")\n",
        "            else:\n",
        "                print(\"We fell into a hole ☠️\")\n",
        "\n",
        "            # We print the number of step it took.\n",
        "            print(\"Number of steps\", step)\n",
        "\n",
        "            break\n",
        "        state = new_state\n",
        "env.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sa2_qVvvhlyu",
        "outputId": "cbf66c84-c17d-486a-b440-8d828b27046a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*************************************************\n",
            "Episode:  0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:49: DeprecationWarning: \u001b[33mWARN: You are calling render method, but you didn't specified the argument render_mode at environment initialization. To maintain backward compatibility, the environment will render in human mode.\n",
            "If you want to render in human mode, initialize the environment in this way: gym.make('EnvName', render_mode='human') and don't call the render method.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We reached our Goal 🏆 \n",
            "Number of steps 15\n",
            "*************************************************\n",
            "Episode:  1\n",
            "We fell into a hole ☠️\n",
            "Number of steps 30\n",
            "*************************************************\n",
            "Episode:  2\n",
            "We fell into a hole ☠️\n",
            "Number of steps 39\n",
            "*************************************************\n",
            "Episode:  3\n",
            "We fell into a hole ☠️\n",
            "Number of steps 21\n",
            "*************************************************\n",
            "Episode:  4\n",
            "We fell into a hole ☠️\n",
            "Number of steps 51\n",
            "*************************************************\n",
            "Episode:  5\n",
            "We fell into a hole ☠️\n",
            "Number of steps 29\n",
            "*************************************************\n",
            "Episode:  6\n",
            "We reached our Goal 🏆 \n",
            "Number of steps 21\n",
            "*************************************************\n",
            "Episode:  7\n",
            "We reached our Goal 🏆 \n",
            "Number of steps 33\n",
            "*************************************************\n",
            "Episode:  8\n",
            "We fell into a hole ☠️\n",
            "Number of steps 8\n",
            "*************************************************\n",
            "Episode:  9\n",
            "We fell into a hole ☠️\n",
            "Number of steps 23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XMalJrrgrY5Y"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}